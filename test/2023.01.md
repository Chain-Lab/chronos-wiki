# 2023.01 测试文档

截止到该测试文档编写前平均 TPS 达到200，其版本代码中修改了共识算法的设计和交易池的打包逻辑

![block-time-result-1672291952.072139](https://imgs.decision01.com/202212291338425.png)

## 测试方案 V2

修改交易池逻辑：每个交易加入时设置其标记为当前交易池的高度，在打包的时候根据交易池高度，只打包高度小于等于当前高度的交易

在修改该逻辑后，可以在插入交易到交易池的同时，从交易池中打包交易。**交易只有在区块插入数据库时从交易池中移除**

<img src="https://imgs.decision01.com/%E4%BA%A4%E6%98%93%E6%B1%A0%E6%89%93%E5%8C%85%20v2.jpg" alt="交易池打包 v2" style="zoom:18%;" />

其次，生成交易不再每次拉取utxo再创建交易，而是分发足够的utxo之后，获取单次utxo，遍历utxo列表使用每笔utxo发送交易

<img src="https://imgs.decision01.com/Chronos%20Documents.jpg" alt="Chronos Documents" style="zoom:18%;" />

## 测试记录

在交易池修改打包逻辑后，可以移除掉原来的锁（这个锁在交易池打包时锁住，rpc线程到达这里会等待打包完成后才能将交易添加到交易池中）

在没有移除锁之前，提交交易的线程一直被频繁打包的线程锁住

![block-time-result-1672998353.5278099](https://imgs.decision01.com/block-time-result-1672998353.5278099.png)

![QQ20230113-094418@2x](https://imgs.decision01.com/QQ20230113-094418@2x.png)

在修改逻辑后，频繁打包区块导致 UTxO 线程不能持续运行，这使得分发过程需要很久，于是去除了 UTxO 更新线程的等待打包逻辑

在该条件下测试，平均的 tps 不能很好地反映节点的处理极限，新增一个指标：最近五个区块处理的tps来观察节点的处理峰值

![block-time-result-1673527093.8763926](https://imgs.decision01.com/block-time-result-1673527093.8763926.png)

![QQ20230113-113743@2x](https://imgs.decision01.com/QQ20230113-113743@2x.png)

但是 UTxO 的更新在整个程序运行的过程中占用就较多的cpu时间片，而且交易池收集交易和每次打包的区块平均在每秒500笔交易，在当前的处理条件下已经到达极限。而且当前的处理过程还去除了 VDF 的计算这一占用过多 cpu 时间片的线程。

后续需要将多线程改为多进程观察处理情况，改为多进程需要考虑对象资源的共享以及进程之间的通信。在多进程下单例模式不能起到作用，只能重新设计代码逻辑来满足多进程需求，目前的大体思路：

* 进程1: 运行 Kademlia 协议，在该进程上运行 Client 和 Server 的多个线程，管理整体区块的更新和收集的类 Manager 是否需要加入待考虑
* 进程2: 进行 VDF 的计算，并且在每次计算完成后通过管道发送计算结果给 进程1 。然后，需要一个管道用来接收其他节点发来的区块中的结果用于验证和开始新一轮的计算
* 进程3: 交易池打包（是否需要单个进程来进行打包也需要考虑）和交易的接收，将 rpc 服务器的线程运行在该进程下，和 进程1 的交互逻辑还需要考虑
* 进程4: 区块、交易的缓存，负责处理 UTxO 持久化到数据库

还需要设计各个进程之间共享一个缓存结构，存储交易、区块，也可以考虑将这个缓存结构作为 UTxO 更新的 进程4，专门接收区块，放入到缓存供其他进程来访问和写入。
